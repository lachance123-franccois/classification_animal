# classification_animal
Ce projet vise à classifier des images d’animaux en utilisant le modèle ResNet18 pré-entraîné sur ImageNet. Il illustre comment combiner prétraitement de données, fine-tuning et évaluation sur un petit dataset pour obtenir des performances élevées.
Le projet démontre que même avec un dataset relativement restreint (≈6 000 images), il est possible d’atteindre une précision élevée (97% sur le test set) grâce à l’utilisation de modèles pré-entraînés et au fine-tuning.
    . Fine-tuning : Le modèle ResNet18 est adapté à notre dataset en ne réentraînant que la couche fully connected. Cela permet de capitaliser sur la capacité de généralisation du modèle pré-entraîné, évitant ainsi un apprentissage complet from scratch, qui serait inefficace sur un petit dataset.
   .  Dataset : Inspiré du dataset “Papillons” disponible sur Kaggle, nous avons structuré les images en sous-dossiers par classe et généré un fichier dataset.csv listant le chemin des images et les labels numériques correspondants.
   Technologies utilisées
Python est langage principal pour le traitement des données et l’entraînement du modèle.PyTorch & Torchvision, framework de deep learning pour la construction, le fine-tuning et l’inférence du modèle ResNet18. Scikit-learn pour le split du dataset en ensembles train, validation et test. Pandas pour gérer le CSV et manipuler les métadonnées des images.Pillow (PIL) lecture et transformation des images. Matplotlib pour visualisation des courbes de loss et accuracy.OS & CSV pour  gestion des fichiers et génération du CSV. Chaque classe d’animaux est placée dans un sous-dossier sous datas/.Le script aninal.py crée automatiquement un fichier CSV (dataset.csv) à deux colonnes,"label_paths" qui est chemin complet vers chaque image,"targets"  qui est  label numérique associé à chaque classe
Les images sont redimensionnées à 224x224 pixels, normalisées selon les paramètres ImageNet, puis converties en tenseurs PyTorch. Partition du dataset avec 60 % pour l’entraînement, 20 % pour la validation, 20 % pour le test, le Modèle ResNet18 avec poids pré-entraînés, seule la dernière couche fully connected est entraînée. Adam avec learning rate 0.001.Fonction de perte  "CrossEntropyLoss". À chaque époque, le script calcule la loss et l’accuracy pour train et validation, puis teste sur le jeu de test final. On a  97 % de précision sur le test set, démontrant la capacité de généralisation du modèle malgré un dataset limité
